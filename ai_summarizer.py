"""
AI æ€»ç»“æ¨¡å— â€” ä¸‰é˜¶æ®µç®¡çº¿

Stage 1  Gemini           éŸ³é¢‘è½¬å†™ + åˆç¨¿æ€»ç»“
Stage 2  DeepSeek Reasoner å¯¹åˆç¨¿è¿›è¡Œæ·±åº¦å®¡è§†ã€æå‡ºè¡¥å……é—®é¢˜
Stage 3  Sonnet 4.5        è”ç½‘æœç´¢è¡¥å……ä¿¡æ¯, è¾“å‡ºæœ€ç»ˆç‰ˆ Markdown

æœ¬æ¨¡å—åªè´Ÿè´£ç”Ÿæˆ Markdown æ–‡æœ¬, PDF æ¸²æŸ“ç”± pdf_generator.py è´Ÿè´£ã€‚
"""
import base64
import os
import logging
import httpx
from config import (
    API_BASE_URL,
    GEMINI_API_KEY, GEMINI_MODEL,
    DEEPSEEK_API_KEY, DEEPSEEK_MODEL,
    SONNET_API_KEY, SONNET_MODEL,
)

logger = logging.getLogger(__name__)

# ============================================================
# å…¬å…± API è°ƒç”¨
# ============================================================

async def _chat(
    model: str,
    messages: list,
    api_key: str,
    max_tokens: int = 8192,
    temperature: float = 0.3,
    timeout: int = 180,
) -> str:
    """ç»Ÿä¸€çš„ OpenAI å…¼å®¹ chat/completions è°ƒç”¨"""
    url = f"{API_BASE_URL}/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": model,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature,
    }

    async with httpx.AsyncClient(timeout=timeout) as client:
        resp = await client.post(url, headers=headers, json=payload)
        resp.raise_for_status()
        data = resp.json()

    return data["choices"][0]["message"]["content"]


# ============================================================
# Stage 1 â€” Gemini: è½¬å†™ + åˆç¨¿
# ============================================================

STAGE1_SYSTEM = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹è½¬å†™ä¸æ€»ç»“åŠ©æ‰‹ã€‚

è¯·å®Œæˆä¸¤ä»¶äº‹ï¼š
1. å®Œæ•´è½¬å†™éŸ³é¢‘ä¸­çš„æ‰€æœ‰å£è¿°å†…å®¹ï¼ˆä¸è¦é—æ¼ä»»ä½•è§‚ç‚¹ã€æ•°æ®ã€æ¡ˆä¾‹ï¼‰
2. åŸºäºè½¬å†™å†…å®¹ï¼Œè¾“å‡ºä¸€ä»½ç»“æ„åŒ–çš„ Markdown å­¦ä¹ ç¬”è®°

## è¾“å‡ºæ ¼å¼

# è§†é¢‘æ ‡é¢˜

> æ ¸å¿ƒæ‘˜è¦ï¼šä¸€å¥è¯æ¦‚æ‹¬

## æ ¸å¿ƒè¦ç‚¹
1. **è¦ç‚¹ä¸€**ï¼šè¯´æ˜
2. **è¦ç‚¹äºŒ**ï¼šè¯´æ˜
...

## è¯¦ç»†ç¬”è®°

### å°èŠ‚æ ‡é¢˜
- å…·ä½“å†…å®¹...
- å…³é”®æ•°æ®/æ¡ˆä¾‹...

ï¼ˆæŒ‰è§†é¢‘é€»è¾‘åˆ†å¤šä¸ªå°èŠ‚ï¼‰

## å…³é”®æ”¶è·
1. ...
2. ...

## åŸå§‹è½¬å†™æ–‡æœ¬
> åœ¨æ­¤å¤„æ”¾ç½®å®Œæ•´çš„é€å­—è½¬å†™å†…å®¹ï¼Œç”¨å¼•ç”¨å—åŒ…è£¹ã€‚

---

## è§„èŒƒ
- **åŠ ç²—**æ˜Ÿå·ç´§è´´æ–‡å­—
- åˆ—è¡¨é¡¹ `- ` æˆ– `1. ` åå¿…é¡»æœ‰ç©ºæ ¼
- æ ‡é¢˜ `#` åå¿…é¡»æœ‰ç©ºæ ¼
- ä½¿ç”¨ä¸­æ–‡ï¼Œä¿ç•™ä¸“ä¸šæœ¯è¯­å¹¶ç»™å‡ºè§£é‡Š
- å°½å¯èƒ½ä¿ç•™è§†é¢‘ä¸­æåˆ°çš„æ‰€æœ‰å…·ä½“æ•°å­—ã€äººåã€ä¹¦åã€æ¡ˆä¾‹
"""


async def stage1_transcribe_and_draft(
    audio_path: str,
    video_title: str = "",
    video_author: str = "",
    user_requirement: str = "",
) -> str:
    """Gemini å¤šæ¨¡æ€: éŸ³é¢‘ â†’ è½¬å†™+åˆç¨¿ Markdown"""
    logger.info("[Stage1] Gemini è½¬å†™+åˆç¨¿")

    file_size = os.path.getsize(audio_path)
    if file_size > 24 * 1024 * 1024:
        return await _stage1_large_audio(audio_path, video_title, video_author, user_requirement)

    with open(audio_path, "rb") as f:
        audio_b64 = base64.b64encode(f.read()).decode()

    user_parts = _build_context(video_title, video_author, user_requirement)

    messages = [
        {"role": "system", "content": STAGE1_SYSTEM},
        {
            "role": "user",
            "content": [
                {"type": "input_audio", "input_audio": {"data": audio_b64, "format": "mp3"}},
                {"type": "text", "text": user_parts},
            ],
        },
    ]

    try:
        result = await _chat(GEMINI_MODEL, messages, GEMINI_API_KEY, timeout=240)
        logger.info(f"[Stage1] å®Œæˆ, é•¿åº¦={len(result)}")
        return result
    except Exception as e:
        logger.warning(f"[Stage1] å¤šæ¨¡æ€å¤±è´¥, å›é€€è½¬å†™+æ€»ç»“: {e}")
        return await _stage1_fallback(audio_path, video_title, video_author, user_requirement)


async def _stage1_fallback(audio_path, title, author, req) -> str:
    """å›é€€: whisper è½¬å†™ â†’ æ–‡æœ¬æ€»ç»“"""
    transcript = await _transcribe_audio(audio_path)
    prompt = _build_context(title, author, req)
    prompt += f"\n\nä»¥ä¸‹æ˜¯è§†é¢‘çš„å®Œæ•´è½¬å†™æ–‡æœ¬:\n\n{transcript}"
    messages = [
        {"role": "system", "content": STAGE1_SYSTEM},
        {"role": "user", "content": prompt},
    ]
    return await _chat(GEMINI_MODEL, messages, GEMINI_API_KEY)


async def _stage1_large_audio(audio_path, title, author, req) -> str:
    """å¤§éŸ³é¢‘: åˆ†æ®µè½¬å†™ â†’ åˆå¹¶ â†’ æ€»ç»“"""
    import subprocess
    probe = subprocess.run(
        ["ffprobe", "-v", "error", "-show_entries", "format=duration",
         "-of", "default=noprint_wrappers=1:nokey=1", audio_path],
        capture_output=True, text=True, timeout=10,
    )
    duration = float(probe.stdout.strip())

    segments, start, i = [], 0, 0
    while start < duration:
        seg = audio_path.replace(".mp3", f"_seg{i}.mp3")
        subprocess.run(
            ["ffmpeg", "-ss", str(start), "-i", audio_path, "-t", "600",
             "-acodec", "libmp3lame", "-ab", "128k", "-y", seg],
            capture_output=True, timeout=60,
        )
        if os.path.exists(seg):
            segments.append(seg)
        start += 600
        i += 1

    parts = []
    for seg in segments:
        try:
            parts.append(await _transcribe_audio(seg))
        except Exception as e:
            logger.warning(f"åˆ†æ®µè½¬å†™å¤±è´¥: {e}")
        finally:
            try:
                os.remove(seg)
            except OSError:
                pass

    transcript = "\n".join(parts)
    prompt = _build_context(title, author, req)
    prompt += f"\n\nä»¥ä¸‹æ˜¯è§†é¢‘çš„å®Œæ•´è½¬å†™æ–‡æœ¬:\n\n{transcript}"
    messages = [
        {"role": "system", "content": STAGE1_SYSTEM},
        {"role": "user", "content": prompt},
    ]
    return await _chat(GEMINI_MODEL, messages, GEMINI_API_KEY)


async def _transcribe_audio(audio_path: str) -> str:
    """whisper API è½¬å†™"""
    url = f"{API_BASE_URL}/audio/transcriptions"
    headers = {"Authorization": f"Bearer {GEMINI_API_KEY}"}
    try:
        async with httpx.AsyncClient(timeout=180) as client:
            with open(audio_path, "rb") as f:
                resp = await client.post(
                    url, headers=headers,
                    files={"file": (os.path.basename(audio_path), f, "audio/mpeg")},
                    data={"model": "whisper-1", "language": "zh", "response_format": "text"},
                )
                resp.raise_for_status()
                return resp.text
    except Exception as e:
        logger.warning(f"whisper å¤±è´¥, ç”¨ Gemini å…œåº•: {e}")
        with open(audio_path, "rb") as f:
            b64 = base64.b64encode(f.read()).decode()
        messages = [
            {"role": "system", "content": "å®Œæ•´è½¬å†™éŸ³é¢‘ä¸ºä¸­æ–‡æ–‡æœ¬ï¼Œåªè¾“å‡ºè½¬å†™å†…å®¹ã€‚"},
            {"role": "user", "content": [
                {"type": "input_audio", "input_audio": {"data": b64, "format": "mp3"}},
                {"type": "text", "text": "è¯·è½¬å†™ã€‚"},
            ]},
        ]
        return await _chat(GEMINI_MODEL, messages, GEMINI_API_KEY, temperature=0.1)


# ============================================================
# Stage 2 â€” DeepSeek Reasoner: æ·±åº¦å®¡è§†
# ============================================================

STAGE2_SYSTEM = """ä½ æ˜¯ä¸€ä½åšå­¦ä¸¥è°¨çš„çŸ¥è¯†å®¡è®¡ä¸“å®¶ã€‚ä½ å°†æ”¶åˆ°ä¸€ä»½ AI æ ¹æ®è§†é¢‘éŸ³é¢‘ç”Ÿæˆçš„å­¦ä¹ ç¬”è®°åˆç¨¿ã€‚

ä½ çš„ä»»åŠ¡æ˜¯å¯¹è¿™ä»½åˆç¨¿è¿›è¡Œ **æ·±åº¦å®¡è§†**ï¼Œæå‡ºæœ‰ä»·å€¼çš„è¡¥å……é—®é¢˜å’Œæ”¹è¿›å»ºè®®ï¼Œå¸®åŠ©åç»­ AI å°†è¿™ä»½ç¬”è®°ä»"æµ…å±‚æ¦‚æ‹¬"æå‡ä¸º"æ·±åº¦å­¦ä¹ èµ„æ–™"ã€‚

## ä½ å¿…é¡»å®Œæˆä»¥ä¸‹åˆ†æ

### ä¸€ã€å†…å®¹ç¼ºå¤±å®¡æŸ¥
é€ä¸€æ£€æŸ¥ç¬”è®°ä¸­æåˆ°ä½†æœªå±•å¼€çš„ï¼š
- ä¸“ä¸šæœ¯è¯­ / æ¦‚å¿µï¼šæ˜¯å¦ç»™å‡ºäº†å‡†ç¡®å®šä¹‰ï¼Ÿæ˜¯å¦éœ€è¦è¡¥å……èƒŒæ™¯çŸ¥è¯†ï¼Ÿ
- äººå / æœºæ„ï¼šæ˜¯å¦éœ€è¦è¡¥å……æ­¤äºº/æœºæ„çš„èƒŒæ™¯ä»‹ç»ï¼Ÿ
- æ•°æ® / ç»Ÿè®¡ï¼šæ˜¯å¦ç¼ºä¹æ¥æºæˆ–å¯¹æ¯”æ•°æ®ï¼Ÿ
- æ¡ˆä¾‹ / äº‹ä»¶ï¼šæ˜¯å¦éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡ï¼Ÿ
- æ–¹æ³•è®º / æ¡†æ¶ï¼šæ˜¯å¦ç»™å‡ºäº†å¯æ“ä½œçš„æ­¥éª¤ï¼Ÿ

### äºŒã€æ·±åº¦ä¸è¶³è¯Šæ–­
- ç¬”è®°ä¸­å“ªäº›è®ºç‚¹åªæœ‰"ç»“è®º"æ²¡æœ‰"è®ºè¯è¿‡ç¨‹"ï¼Ÿ
- å“ªäº›å»ºè®®å¤ªç¬¼ç»Ÿï¼Œéœ€è¦é‡åŒ–æˆ–å…·ä½“åŒ–ï¼Ÿ
- æ˜¯å¦å­˜åœ¨å€¼å¾—å¯¹æ¯”è®¨è®ºçš„åé¢è§‚ç‚¹æˆ–äº‰è®®ï¼Ÿ

### ä¸‰ã€çŸ¥è¯†æ‹“å±•å»ºè®®
- è§†é¢‘ä¸»é¢˜å…³è”çš„é‡è¦æ¦‚å¿µ/ç†è®ºï¼Œç¬”è®°ä¸­å®Œå…¨æ²¡æœ‰æåŠä½†å­¦ä¹ è€…åº”è¯¥çŸ¥é“çš„
- æ¨èçš„å»¶ä¼¸é˜…è¯»æ–¹å‘

## è¾“å‡ºæ ¼å¼

ä¸¥æ ¼ä½¿ç”¨ä»¥ä¸‹ Markdown æ ¼å¼è¾“å‡ºï¼š

# å®¡æŸ¥æŠ¥å‘Š

## éœ€è¦è¡¥å……è§£é‡Šçš„æ¦‚å¿µ
1. **[æ¦‚å¿µåç§°]** â€” ä¸ºä»€ä¹ˆéœ€è¦è¡¥å…… + å»ºè®®æœç´¢çš„å…³é”®è¯
2. ...

## éœ€è¦è¡¥å……çš„èƒŒæ™¯ä¿¡æ¯
1. **[äººå/æœºæ„/äº‹ä»¶]** â€” éœ€è¦è¡¥å……ä»€ä¹ˆ + å»ºè®®æœç´¢å…³é”®è¯
2. ...

## éœ€è¦æ·±åŒ–çš„è®ºç‚¹
1. **[è®ºç‚¹]** â€” å½“å‰é—®é¢˜ + å¦‚ä½•æ”¹è¿›
2. ...

## å»ºè®®è¡¥å……çš„å…³è”çŸ¥è¯†
1. **[çŸ¥è¯†ç‚¹]** â€” ä¸è§†é¢‘ä¸»é¢˜çš„å…³è” + æœç´¢å…³é”®è¯
2. ...

## å…·ä½“æœç´¢ä»»åŠ¡æ¸…å•
æŒ‰ä¼˜å…ˆçº§åˆ—å‡º 5-10 ä¸ªæœ€å€¼å¾—æœç´¢è¡¥å……çš„æ¡ç›®ï¼š
1. æœç´¢: "[å…·ä½“æœç´¢å…³é”®è¯]" â€” ç”¨äºè¡¥å…… [ä»€ä¹ˆå†…å®¹]
2. ...

æ³¨æ„ï¼š
- æ¯æ¡å»ºè®®éƒ½å¿…é¡»é™„å¸¦ **å…·ä½“çš„æœç´¢å…³é”®è¯**ï¼Œæ–¹ä¾¿ä¸‹æ¸¸ AI ç›´æ¥æ‰§è¡Œæœç´¢
- ä¼˜å…ˆå…³æ³¨è§†é¢‘æ ¸å¿ƒä¸»é¢˜ç›¸å…³çš„é—®é¢˜ï¼Œä¸è¦çº ç»“è¾¹ç¼˜ç»†èŠ‚
- å¦‚æœåˆç¨¿è´¨é‡å·²ç»å¾ˆé«˜æŸæ–¹é¢æ— éœ€è¡¥å……ï¼Œè¯·ç›´æ¥è¯´"æ­¤æ–¹é¢æ— éœ€è¡¥å……"
"""


async def stage2_critical_review(draft_markdown: str) -> str:
    """DeepSeek Reasoner å¯¹åˆç¨¿è¿›è¡Œæ·±åº¦å®¡è§†"""
    logger.info("[Stage2] DeepSeek æ·±åº¦å®¡è§†")

    messages = [
        {"role": "system", "content": STAGE2_SYSTEM},
        {
            "role": "user",
            "content": (
                "ä»¥ä¸‹æ˜¯ AI æ ¹æ®ä¸€ä¸ªçŸ¥è¯†è§†é¢‘ç”Ÿæˆçš„å­¦ä¹ ç¬”è®°åˆç¨¿ï¼Œè¯·è¿›è¡Œæ·±åº¦å®¡è§†ï¼š\n\n"
                "---\n\n"
                f"{draft_markdown}\n\n"
                "---\n\n"
                "è¯·æŒ‰ç…§è¦æ±‚è¾“å‡ºå®¡æŸ¥æŠ¥å‘Šã€‚"
            ),
        },
    ]

    result = await _chat(DEEPSEEK_MODEL, messages, DEEPSEEK_API_KEY, max_tokens=4096, temperature=0.2, timeout=300)
    logger.info(f"[Stage2] å®Œæˆ, é•¿åº¦={len(result)}")
    return result


# ============================================================
# Stage 3 â€” Sonnet 4.5: è”ç½‘æœç´¢ + æœ€ç»ˆç‰ˆ
# ============================================================

STAGE3_SYSTEM = """ä½ æ˜¯ä¸€ä½é¡¶çº§çŸ¥è¯†ç¼–è¾‘ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†åˆç¨¿é‡å†™ä¸ºä¸€ä»½ **å®Œæ•´ã€æ·±å…¥ã€æ ·å¼ç²¾ç¾** çš„æœ€ç»ˆç‰ˆè§†é¢‘ç¬”è®°ã€‚

## æ ¸å¿ƒåŸåˆ™

1. **ç»“æ„ç¬¬ä¸€**ï¼šç›´æ¥è¾“å‡ºç¬”è®°å†…å®¹ï¼Œ**ä¸¥ç¦**è¾“å‡º"æ ¹æ®æ‚¨çš„è¦æ±‚..."ã€"æ‰§è¡Œæœç´¢ä»»åŠ¡..."ç­‰ä»»ä½•å…ƒè¯´æ˜ã€‚
2. **æ ·å¼è§„èŒƒ**ï¼š
   - **æ­£æ–‡**ï¼šä½¿ç”¨æ ‡å‡†æ®µè½ï¼Œ**ä¸¥ç¦**ä½¿ç”¨å¼•ç”¨å—ï¼ˆ`> `ï¼‰åŒ…è£¹æ­£æ–‡ï¼ˆè¿™ä¼šå¯¼è‡´è“è‰²æ¡†ï¼‰ã€‚
   - **é‡ç‚¹/è¡¥å……**ï¼šä»…åœ¨"çŸ¥è¯†è¡¥å……"æˆ–"æ ¸å¿ƒæ‘˜è¦"å¤„ä½¿ç”¨å¼•ç”¨å—ã€‚
   - **æ•°å­¦å…¬å¼**ï¼šæ”¯æŒ LaTeX æ ¼å¼
     - è¡Œå†…å…¬å¼ï¼šä½¿ç”¨ `$å…¬å¼$`ï¼ˆå¦‚ `$E=mc^2$`ï¼‰
     - å—çº§å…¬å¼ï¼šä½¿ç”¨ `$$å…¬å¼$$` æˆ–ä»£ç å— ` ```math `
     - **é‡è¦ç¦æ­¢**ï¼šè‹¥å…¬å¼ä¸­åŒ…å«**ä¸­æ–‡**å­—ç¬¦ï¼Œ**ä¸¥ç¦**ä½¿ç”¨ LaTeX æ ¼å¼ï¼ˆå› ä¸º PDF æ¸²æŸ“å™¨ä¸æ”¯æŒ LaTeX ä¸­æ–‡ï¼‰ã€‚è¯·ç›´æ¥ä½¿ç”¨æ™®é€šæ–‡æœ¬è¾“å‡ºè¯¥å…¬å¼ã€‚
   - **åˆ—è¡¨**ï¼šä½¿ç”¨ `- ` å¼€å¤´ï¼ˆçŸ­æ¨ªçº¿åå¿…é¡»æœ‰ç©ºæ ¼ï¼‰ï¼Œä¸è¦ç”¨ `* `
3. **å†…å®¹æ·±åº¦**ï¼šè§£é‡Šæ‰€æœ‰ä¸“ä¸šåè¯ï¼Œè¡¥å……èƒŒæ™¯çŸ¥è¯†ã€‚
4. **ä½œè€…ä¿¡æ¯**ï¼šä»åˆç¨¿ä¸­æå–è§†é¢‘ä½œè€…åç§°ã€‚å¦‚æœåˆç¨¿æœªæä¾›ä½œè€…ä¿¡æ¯ï¼Œåˆ™å®Œå…¨çœç•¥"è§†é¢‘ä½œè€…"è¿™ä¸€è¡Œï¼Œä¸è¦å†™å ä½ç¬¦ã€‚

## è¾“å‡ºç»“æ„ï¼ˆä¸¥æ ¼éµå®ˆï¼‰

# [è§†é¢‘æ ‡é¢˜]

> **æ ¸å¿ƒæ‘˜è¦**ï¼š[1-2å¥è¯]
> **è§†é¢‘ä½œè€…**ï¼š[ä»åˆç¨¿æå–çš„ä½œè€…åï¼Œå¦‚æ— åˆ™åˆ é™¤æ­¤è¡Œ]

## 1. [å°èŠ‚æ ‡é¢˜]

[æ­£æ–‡æ®µè½ï¼Œä¸è¦ç”¨å¼•ç”¨å—...]

- [åˆ—è¡¨é¡¹1]
- [åˆ—è¡¨é¡¹2]

## 2. [å°èŠ‚æ ‡é¢˜]

[æ­£æ–‡æ®µè½...]

```math
[å¤æ‚å…¬å¼æ”¾å…¥ä»£ç å—]
```

> ğŸ’¡ **çŸ¥è¯†è¡¥å……**ï¼š[è¡¥å……ä¿¡æ¯]

...

## å…³é”®æ”¶è·
1. ...
2. ...

## å»¶ä¼¸é˜…è¯»
- ...

<!-- æœç´¢å…³é”®è¯æ¸…å•ï¼ˆæ”¾åœ¨æœ€åï¼Œä¸å½±å“é˜…è¯»ï¼‰ -->
## é™„ï¼šæœç´¢å…³é”®è¯
- ...
"""


async def stage3_enrich_and_finalize(
    draft_markdown: str,
    review_report: str,
    user_requirement: str = "",
) -> str:
    """Sonnet 4.5 è”ç½‘æœç´¢è¡¥å……ä¿¡æ¯, ç”Ÿæˆæœ€ç»ˆç‰ˆ"""
    logger.info("[Stage3] Sonnet è”ç½‘æœç´¢ + æœ€ç»ˆç‰ˆ")

    user_content = (
        "## åˆç¨¿\n\n"
        f"{draft_markdown}\n\n"
        "---\n\n"
        "## å®¡æŸ¥æŠ¥å‘Š\n\n"
        f"{review_report}\n\n"
        "---\n\n"
    )
    if user_requirement:
        user_content += f"## ç”¨æˆ·ç‰¹åˆ«è¦æ±‚\n\n{user_requirement}\n\n---\n\n"

    user_content += (
        "è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å¤„ç†ï¼š\n"
        "1. é˜…è¯»å®¡æŸ¥æŠ¥å‘Šä¸­çš„æœç´¢ä»»åŠ¡æ¸…å•\n"
        "2. å¯¹æ¯ä¸ªé‡è¦æ¡ç›®æ‰§è¡Œ web_search æœç´¢\n"
        "3. å°†æœç´¢ç»“æœèå…¥åˆç¨¿\n"
        "4. è¾“å‡ºæœ€ç»ˆç‰ˆç¬”è®°ï¼ˆ**ç›´æ¥ä»¥æ ‡é¢˜å¼€å§‹ï¼Œä¸è¦æœ‰ä»»ä½•å¼€åœºç™½**ï¼‰\n\n"
        "å¼€å§‹å§ã€‚"
    )

    messages = [
        {"role": "system", "content": STAGE3_SYSTEM},
        {"role": "user", "content": user_content},
    ]

    # Sonnet with web_search tool
    url = f"{API_BASE_URL}/chat/completions"
    headers = {
        "Authorization": f"Bearer {SONNET_API_KEY}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": SONNET_MODEL,
        "messages": messages,
        "max_tokens": 12000,
        "temperature": 0.3,
        "tools": [
            {
                "type": "web_search_20250305",
                "name": "web_search",
            }
        ],
    }

    async with httpx.AsyncClient(timeout=300) as client:
        resp = await client.post(url, headers=headers, json=payload)
        resp.raise_for_status()
        data = resp.json()

    # æå–æ–‡æœ¬å†…å®¹ (å¯èƒ½æ··æœ‰ tool_use blocks)
    content_blocks = data["choices"][0]["message"].get("content", "")
    if isinstance(content_blocks, list):
        result = "\n".join(
            block.get("text", "") for block in content_blocks if block.get("type") == "text"
        )
    else:
        result = content_blocks

    logger.info(f"[Stage3] å®Œæˆ, é•¿åº¦={len(result)}")
    return result


# ============================================================
# ä¸»å…¥å£
# ============================================================

async def summarize_with_audio(
    audio_path: str,
    video_title: str = "",
    video_author: str = "",
    user_requirement: str = "",
    progress_callback=None,
) -> str:
    """
    ä¸‰é˜¶æ®µ AI ç®¡çº¿, è¿”å›æœ€ç»ˆç‰ˆ Markdown

    progress_callback: async callable(str) ç”¨äºå‘ç”¨æˆ·æ¨é€è¿›åº¦
    """
    async def notify(msg: str):
        if progress_callback:
            try:
                await progress_callback(msg)
            except Exception:
                pass

    # Stage 1
    await notify("ğŸ”¬ [1/3] Gemini æ­£åœ¨è½¬å†™éŸ³é¢‘å¹¶ç”Ÿæˆåˆç¨¿...")
    draft = await stage1_transcribe_and_draft(
        audio_path, video_title, video_author, user_requirement,
    )
    await notify("âœ… [1/3] åˆç¨¿ç”Ÿæˆå®Œæˆ")

    # Stage 2
    await notify("ğŸ§  [2/3] DeepSeek æ­£åœ¨æ·±åº¦å®¡è§†åˆç¨¿...")
    review = await stage2_critical_review(draft)
    await notify("âœ… [2/3] å®¡æŸ¥æŠ¥å‘Šç”Ÿæˆå®Œæˆ")

    # Stage 3
    await notify("ğŸŒ [3/3] Sonnet æ­£åœ¨è”ç½‘æœç´¢å¹¶ç”Ÿæˆæœ€ç»ˆç‰ˆ...")
    final = await stage3_enrich_and_finalize(draft, review, user_requirement)
    await notify("âœ… [3/3] æœ€ç»ˆç‰ˆç¬”è®°ç”Ÿæˆå®Œæˆ")

    return final


# ============================================================
# è¾…åŠ©
# ============================================================

def _build_context(title: str, author: str, requirement: str) -> str:
    parts = ["è¯·å¯¹ä»¥ä¸‹è§†é¢‘å†…å®¹è¿›è¡Œè½¬å†™å’Œæ€»ç»“ï¼š"]
    if title:
        parts.append(f"è§†é¢‘æ ‡é¢˜ï¼š{title}")
    if author:
        parts.append(f"ä½œè€…ï¼š{author}")
    if requirement:
        parts.append(f"\nç”¨æˆ·çš„ç‰¹åˆ«è¦æ±‚ï¼š{requirement}")
    else:
        parts.append("\nè¯·æŒ‰ç…§é»˜è®¤æ ¼å¼è¿›è¡Œå…¨é¢æ€»ç»“ã€‚")
    return "\n".join(parts)
