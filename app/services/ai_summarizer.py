"""AI æ€»ç»“æ¨¡å— (Gemini + Qwen + Sonnet)"""
import base64
import os
import logging
import httpx
from openai import OpenAI

from app.config import (
    API_BASE_URL,
    GEMINI_API_KEY, GEMINI_MODEL,
    DASHSCOPE_API_KEY, QWEN_MODEL, QWEN_API_BASE,
    SONNET_API_KEY, SONNET_MODEL,
)

logger = logging.getLogger(__name__)


from typing import Optional, Callable

async def _chat(model, messages, api_key, max_tokens=8192, temperature=0.3, timeout=180, callback: Optional[Callable] = None) -> str:
    """OpenAI å…¼å®¹å¯¹è¯æ¥å£ (ç”¨äº Gemini å’Œ Sonnet via uiuiapi)"""
    url = f"{API_BASE_URL}/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": model,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature,
    }

    async with httpx.AsyncClient(timeout=timeout) as client:
        try:
            resp = await client.post(url, headers=headers, json=payload)
            resp.raise_for_status()
            return resp.json()["choices"][0]["message"]["content"]
        except httpx.HTTPStatusError as e:
            # æ•è· 429, 5xx, 3xx è¿›è¡Œé‡è¯•
            if e.response.status_code in (429, 401, 403) or e.response.status_code >= 500 or (300 <= e.response.status_code < 400):
                logger.warning(f"ä¸»ç«™å¼‚å¸¸ ({e.response.status_code})ï¼Œå°è¯•åˆ‡æ¢å‰¯ç«™: {e}")
                if callback: await callback("âš ï¸ ä¸»çº¿è·¯ç¹å¿™ï¼Œæ­£åœ¨åˆ‡æ¢å¤‡ç”¨çº¿è·¯...")
                return await _chat_failover(model, messages, max_tokens, temperature, timeout, callback)
            raise e
        except (httpx.ConnectError, httpx.TimeoutException, httpx.NetworkError) as e:
            logger.warning(f"ä¸»ç«™è¿æ¥å¤±è´¥ ({type(e).__name__})ï¼Œå°è¯•åˆ‡æ¢å‰¯ç«™: {e}")
            if callback: await callback("âš ï¸ ä¸»çº¿è·¯è¿æ¥è¶…æ—¶ï¼Œæ­£åœ¨åˆ‡æ¢å¤‡ç”¨çº¿è·¯...")
            return await _chat_failover(model, messages, max_tokens, temperature, timeout, callback)
        except Exception as e:
            logger.warning(f"ä¸»ç«™æœªçŸ¥å¼‚å¸¸: {e}ï¼Œå°è¯•åˆ‡æ¢å‰¯ç«™...")
            if callback: await callback("âš ï¸ ä¸»çº¿è·¯å¼‚å¸¸ï¼Œæ­£åœ¨åˆ‡æ¢å¤‡ç”¨çº¿è·¯...")
            return await _chat_failover(model, messages, max_tokens, temperature, timeout, callback)


async def _chat_failover(model, messages, max_tokens, temperature, timeout, callback: Optional[Callable] = None) -> str:
    """å‰¯ç«™é‡è¯•é€»è¾‘"""
    from app.config import (
        SECONDARY_API_BASE_URL, 
        SECONDARY_GEMINI_API_KEY, SECONDARY_GEMINI_MODEL,
        SECONDARY_SONNET_API_KEY, SECONDARY_SONNET_MODEL,
        GEMINI_MODEL, SONNET_MODEL
    )

    # ç¡®å®šå‰¯ç«™ Key å’Œ Model
    target_model = model
    api_key = ""

    if model == GEMINI_MODEL:
        api_key = SECONDARY_GEMINI_API_KEY
        target_model = SECONDARY_GEMINI_MODEL
    elif model == SONNET_MODEL:
        api_key = SECONDARY_SONNET_API_KEY
        target_model = SECONDARY_SONNET_MODEL

    if not api_key:
        logger.error(f"æœªé…ç½®å‰¯ç«™ API Key (Model: {model})ï¼Œæ— æ³•åˆ‡æ¢")
        raise ValueError("Failover failed: No secondary key")

    url = f"{SECONDARY_API_BASE_URL}/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": target_model,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature,
    }

    logger.info(f"æ­£åœ¨è¯·æ±‚å‰¯ç«™: {url} (Model: {target_model})")
    async with httpx.AsyncClient(timeout=timeout) as client:
        resp = await client.post(url, headers=headers, json=payload)
        resp.raise_for_status()
        return resp.json()["choices"][0]["message"]["content"]



# ======================== å…¨å±€ Prompt ========================

STAGE1_SYSTEM = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹è½¬å†™ä¸æ€»ç»“åŠ©æ‰‹ã€‚

è¯·å®Œæˆä¸¤ä»¶äº‹ï¼š
1. å®Œæ•´è½¬å†™éŸ³é¢‘ä¸­çš„æ‰€æœ‰å£è¿°å†…å®¹ï¼ˆä¸è¦é—æ¼ä»»ä½•è§‚ç‚¹ã€æ•°æ®ã€æ¡ˆä¾‹ï¼‰
2. åŸºäºè½¬å†™å†…å®¹ï¼Œè¾“å‡ºä¸€ä»½ç»“æ„åŒ–çš„ Markdown å­¦ä¹ ç¬”è®°

## è¾“å‡ºæ ¼å¼
# è§†é¢‘æ ‡é¢˜
> æ ¸å¿ƒæ‘˜è¦ï¼šä¸€å¥è¯æ¦‚æ‹¬
## æ ¸å¿ƒè¦ç‚¹
1. **è¦ç‚¹ä¸€**ï¼šè¯´æ˜
...
## è¯¦ç»†ç¬”è®°
### å°èŠ‚æ ‡é¢˜
- å…·ä½“å†…å®¹...
## å…³é”®æ”¶è·
1. ...
## åŸå§‹è½¬å†™æ–‡æœ¬
> åœ¨æ­¤å¤„æ”¾ç½®å®Œæ•´çš„é€å­—è½¬å†™å†…å®¹ï¼Œç”¨å¼•ç”¨å—åŒ…è£¹ã€‚
"""

STAGE2_SYSTEM = """ä½ æ˜¯ä¸€ä½åšå­¦ä¸¥è°¨çš„çŸ¥è¯†å®¡è®¡ä¸æ·±åº¦ç ”ç©¶ä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å¯¹ AI ç”Ÿæˆçš„åˆç¨¿è¿›è¡Œæ·±åº¦å®¡è§†ï¼Œå¹¶åˆ©ç”¨è”ç½‘æœç´¢å·¥å…·è¿›è¡Œäº‹å®æ ¸æŸ¥å’ŒçŸ¥è¯†æ‹“å±•ã€‚

æ ¸å¿ƒç›®æ ‡ï¼š
1. **äº‹å®æ ¸æŸ¥**ï¼šéªŒè¯åˆç¨¿ä¸­çš„æ•°æ®ã€æ¡ˆä¾‹å’Œè§‚ç‚¹ã€‚
2. **çŸ¥è¯†æ‹“å±•**ï¼šè¡¥å……åˆç¨¿ä¸­ç¼ºå¤±çš„èƒŒæ™¯ä¿¡æ¯ã€ä¸“ä¸šæœ¯è¯­å®šä¹‰å’Œç›¸å…³é¢†åŸŸçŸ¥è¯†ã€‚
3. **æ·±åº¦ç ”åˆ¤**ï¼šæŒ‡å‡ºåˆç¨¿çš„é€»è¾‘æ¼æ´æˆ–æ·±åº¦ä¸è¶³ä¹‹å¤„ï¼Œå¹¶æä¾›ä¿®æ­£å»ºè®®ã€‚

è¯·ç§¯æä½¿ç”¨å·¥å…·æœç´¢ä¿¡æ¯ã€‚æœç´¢å®Œæˆåï¼Œè¯·è¾“å‡ºä¸€ä»½è¯¦å°½çš„ã€Šæ·±åº¦ç ”ç©¶æŠ¥å‘Šã€‹ã€‚

## æŠ¥å‘Šæ ¼å¼ (Markdown)
# æ·±åº¦ç ”ç©¶æŠ¥å‘Š

## 1. å…³é”®äº‹å®æ ¸æŸ¥
- **[åŸè§‚ç‚¹/æ•°æ®]**ï¼š...
  - **æ ¸æŸ¥ç»“æœ**ï¼š...
  - **æ¥æº/è¯æ®**ï¼š...

## 2. çŸ¥è¯†èƒŒæ™¯è¡¥å……
- **[æ¦‚å¿µ/æœ¯è¯­]**ï¼šè¯¦ç»†è§£é‡Š...
- **[ç›¸å…³äººç‰©/äº‹ä»¶]**ï¼šä»‹ç»...

## 3. æ·±åº¦ç ”åˆ¤ä¸æ‰©å±•
- ...

## 4. åŸå§‹æœç´¢æ‘˜è¦
(åˆ—å‡ºæœç´¢åˆ°çš„å…³é”®ä¿¡æ¯æ‘˜è¦)
"""

STAGE3_SYSTEM = """ä½ æ˜¯ä¸€ä½é¡¶çº§çŸ¥è¯†ç¼–è¾‘ã€‚è¯·å°†åˆç¨¿å’Œã€Šæ·±åº¦ç ”ç©¶æŠ¥å‘Šã€‹æ•´åˆæˆä¸€ä»½å®Œæ•´ã€æ·±å…¥ã€æ ·å¼ç²¾ç¾çš„æœ€ç»ˆç‰ˆç¬”è®°ã€‚

## æ ¸å¿ƒåŸåˆ™
1. **èåˆé‡å†™**ï¼šä¸è¦ç®€å•æ‹¼æ¥ã€‚å°†ç ”ç©¶æŠ¥å‘Šä¸­çš„æ–°çŸ¥è¯†ã€çº æ­£çš„äº‹å®æœ‰æœºèå…¥åˆ°åˆç¨¿çš„ç»“æ„ä¸­ã€‚
2. **ç»“æ„æ¸…æ™°**ï¼šä½¿ç”¨æ¸…æ™°çš„ Markdown ç»“æ„ (H1, H2, H3)ã€‚
3. **æ ·å¼è§„èŒƒ**ï¼š
   - ä¸¥ç¦æ­£æ–‡ä½¿ç”¨å¼•ç”¨å— (ä¿ç•™ç»™æ‘˜è¦æˆ–ç‰¹åˆ«å¼ºè°ƒ)ã€‚
   - æ•°å­¦å…¬å¼ï¼šè¡Œå†… $...$ (ä¸­æ–‡ç¯å¢ƒç¦æ­¢ LaTeX)ï¼Œå—çº§ $$...$$ã€‚
4. **å†…å®¹æ·±åº¦**ï¼šç¡®ä¿ç¬”è®°å†…å®¹è¯¦å®ï¼Œè§£é‡Šä¸“ä¸šåè¯ï¼Œè¡¥å……èƒŒæ™¯ï¼Œé€»è¾‘ä¸¥å¯†ã€‚

## è¾“å‡ºç»“æ„
# [æ ‡é¢˜]
> **æ ¸å¿ƒæ‘˜è¦**ï¼š...
> **è§†é¢‘ä½œè€…**ï¼š...

## 1. [æ ¸å¿ƒç« èŠ‚]
...

## å»¶ä¼¸é˜…è¯»ä¸èƒŒæ™¯
...
"""


# ======================== Stage 1: Gemini ========================

async def stage1_transcribe_and_draft(audio_path, video_title="", video_author="", user_requirement="", callback: Optional[Callable] = None) -> str:
    """Gemini å¤šæ¨¡æ€: éŸ³é¢‘ â†’ åˆç¨¿"""
    logger.info("[Stage1] Gemini è½¬å†™+åˆç¨¿")

    if os.path.getsize(audio_path) > 24 * 1024 * 1024:
        # å¤§æ–‡ä»¶å›é€€å¤„ç†
        return await _stage1_large_audio(audio_path, video_title, video_author, user_requirement, callback)

    with open(audio_path, "rb") as f:
        audio_b64 = base64.b64encode(f.read()).decode()

    user_parts = _build_context(video_title, video_author, user_requirement)
    messages = [
        {"role": "system", "content": STAGE1_SYSTEM},
        {
            "role": "user",
            "content": [
                {"type": "input_audio", "input_audio": {"data": audio_b64, "format": "mp3"}},
                {"type": "text", "text": user_parts},
            ],
        },
    ]

    try:
        return await _chat(GEMINI_MODEL, messages, GEMINI_API_KEY, timeout=240, callback=callback)
    except Exception as e:
        logger.warning(f"[Stage1] å¤±è´¥ï¼Œå›é€€: {e}")
        return await _stage1_fallback(audio_path, video_title, video_author, user_requirement, callback)


async def _stage1_fallback(audio_path, title, author, req, callback: Optional[Callable] = None) -> str:
    """WHISPER è½¬å†™ + LLM æ€»ç»“"""
    transcript = await _transcribe_audio(audio_path)
    prompt = f"{_build_context(title, author, req)}\n\nè½¬å†™æ–‡æœ¬:\n\n{transcript}"
    messages = [
        {"role": "system", "content": STAGE1_SYSTEM},
        {"role": "user", "content": prompt},
    ]
    return await _chat(GEMINI_MODEL, messages, GEMINI_API_KEY, callback=callback)


async def _stage1_large_audio(audio_path, title, author, req, callback: Optional[Callable] = None) -> str:
    """å¤§æ–‡ä»¶åˆ†æ®µè½¬å†™"""
    import subprocess
    probe = subprocess.run(["ffprobe", "-v", "error", "-show_entries", "format=duration", "-of", "default=noprint_wrappers=1:nokey=1", audio_path], capture_output=True, text=True)
    duration = float(probe.stdout.strip())

    segments, start = [], 0
    while start < duration:
        seg = audio_path.replace(".mp3", f"_seg{int(start)}.mp3")
        subprocess.run(["ffmpeg", "-ss", str(start), "-i", audio_path, "-t", "600", "-acodec", "libmp3lame", "-y", seg], capture_output=True)
        if os.path.exists(seg): segments.append(seg)
        start += 600

    parts = []
    for seg in segments:
        try: parts.append(await _transcribe_audio(seg))
        except: pass
        finally: 
            if os.path.exists(seg): os.remove(seg)

    transcript = "\n".join(parts)
    prompt = f"{_build_context(title, author, req)}\n\nè½¬å†™æ–‡æœ¬:\n\n{transcript}"
    return await _chat(GEMINI_MODEL, [{"role": "system", "content": STAGE1_SYSTEM}, {"role": "user", "content": prompt}], GEMINI_API_KEY, callback=callback)


async def _transcribe_audio(audio_path: str) -> str:
    """Whisper API è½¬å†™"""
    url = f"{API_BASE_URL}/audio/transcriptions"
    headers = {"Authorization": f"Bearer {GEMINI_API_KEY}"}
    try:
        async with httpx.AsyncClient(timeout=180) as client:
            with open(audio_path, "rb") as f:
                resp = await client.post(url, headers=headers, files={"file": (os.path.basename(audio_path), f, "audio/mpeg")}, data={"model": "whisper-1", "language": "zh"})
                resp.raise_for_status()
                return resp.text
    except Exception:
        # Fallback to Gemini Multimodal
        with open(audio_path, "rb") as f: b64 = base64.b64encode(f.read()).decode()
        return await _chat(GEMINI_MODEL, [{"role": "user", "content": [{"type": "input_audio", "input_audio": {"data": b64, "format": "mp3"}}, {"type": "text", "text": "è½¬å†™ä¸ºä¸­æ–‡æ–‡æœ¬"}]}], GEMINI_API_KEY, temperature=0.1)


# ======================== Stage 2: Qwen (Aliyun DashScope) ========================

async def stage2_deep_research(draft_markdown: str) -> str:
    """Qwen æ·±åº¦ç ”ç©¶ (Thinking + Native Tools)"""
    logger.info("[Stage2] Qwen æ·±åº¦ç ”ç©¶ (DashScope)")
    
    client = OpenAI(
        api_key=DASHSCOPE_API_KEY,
        base_url=QWEN_API_BASE,
    )

    messages = [
        {"role": "system", "content": STAGE2_SYSTEM},
        {"role": "user", "content": f"ä»¥ä¸‹æ˜¯åˆç¨¿ï¼Œè¯·è¿›è¡Œæ·±åº¦ç ”åˆ¤å¹¶è¡¥å……çŸ¥è¯†ï¼š\n\n---\n{draft_markdown}\n---\n"},
    ]

    try:
        completion = client.chat.completions.create(
            model=QWEN_MODEL,
            messages=messages,
            extra_body={"enable_search": True}, # å¯ç”¨ Qwen åŸç”Ÿè”ç½‘æœç´¢
            temperature=0.3
        )
        
        # Qwen ä¼šåœ¨å†…éƒ¨è‡ªåŠ¨æ‰§è¡Œæœç´¢å¹¶è¿”å›æœ€ç»ˆç­”æ¡ˆ
        return completion.choices[0].message.content

    except Exception as e:
        logger.error(f"[Stage2] Qwen Error: {e}", exc_info=True)
        return f"æ·±åº¦ç ”ç©¶å¤±è´¥: {str(e)}\n\n(å›é€€åˆ°ä»…ä¾èµ–åˆç¨¿)"


# ======================== Stage 3: Sonnet ========================

async def stage3_enrich_and_finalize(draft_markdown, research_report, video_author="", user_requirement="", callback: Optional[Callable] = None) -> str:
    """Sonnet èåˆåˆç¨¿ä¸ç ”ç©¶æŠ¥å‘Š"""
    logger.info("[Stage3] Sonnet ç»ˆç¨¿ç”Ÿæˆ")
    user_content = f"## åˆç¨¿\n{draft_markdown}\n\n## æ·±åº¦ç ”ç©¶æŠ¥å‘Š\n{research_report}\n"
    if video_author: user_content += f"\n## è§†é¢‘ä½œè€…\n{video_author}\n"
    if user_requirement: user_content += f"\n## ç”¨æˆ·è¦æ±‚\n{user_requirement}\n"
    user_content += "\nè¯·æ•´åˆæ‰€æœ‰ä¿¡æ¯ï¼Œè¾“å‡ºæœ€ç»ˆç‰ˆç¬”è®°ã€‚è¯·ç¡®ä¿åœ¨ç¬”è®°å¼€å¤´çš„æ ¸å¿ƒæ‘˜è¦ä¸‹æ–¹ï¼Œæ˜ç¡®åˆ—å‡ºè§†é¢‘ä½œè€…ã€‚"

    messages = [{"role": "system", "content": STAGE3_SYSTEM}, {"role": "user", "content": user_content}]
    
    # Sonnet çº¯æ–‡æœ¬ç”Ÿæˆ
    return await _chat(SONNET_MODEL, messages, SONNET_API_KEY, max_tokens=8192, temperature=0.3, callback=callback)


async def summarize_with_audio(audio_path, video_title="", video_author="", user_requirement="", progress_callback=None) -> str:
    """ä¸‰é˜¶æ®µ AI æ€»ç»“æµæ°´çº¿"""
    async def notify(msg):
        if progress_callback: await progress_callback(msg)

    await notify("ğŸ”¬ [1/3] Gemini è½¬å†™ç”Ÿæˆåˆç¨¿...")
    draft = await stage1_transcribe_and_draft(audio_path, video_title, video_author, user_requirement, callback=notify)
    
    await notify("ğŸ§  [2/3] Qwen æ·±åº¦æ€è€ƒä¸è”ç½‘ç ”ç©¶...")
    research_report = await stage2_deep_research(draft)
    
    await notify("âœï¸ [3/3] Sonnet æ•´åˆç”Ÿæˆç»ˆç¨¿...")
    final = await stage3_enrich_and_finalize(draft, research_report, video_author, user_requirement, callback=notify)
    
    await notify("âœ… å¤„ç†å®Œæˆ")
    return final


def _build_context(title, author, requirement):
    parts = ["è¯·å¯¹ä»¥ä¸‹è§†é¢‘å†…å®¹è¿›è¡Œè½¬å†™å’Œæ€»ç»“ï¼š"]
    if title: parts.append(f"æ ‡é¢˜ï¼š{title}")
    if author: parts.append(f"ä½œè€…ï¼š{author}")
    if requirement: parts.append(f"\nç”¨æˆ·ç‰¹åˆ«è¦æ±‚ï¼š{requirement}")
    return "\n".join(parts)
